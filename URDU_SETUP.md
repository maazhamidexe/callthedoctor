# Urdu AI Appointment System - Setup Complete âœ…

## Overview
Your AI system now makes **outbound calls in Urdu** on behalf of patients to schedule appointments with clinics. The AI calls the clinic, speaks in Urdu, schedules the appointment, and returns structured data to the server.

## What Changed

### 1. AI Behavior (server.js)
- **Language**: AI now speaks ONLY in Urdu (Ø§Ø±Ø¯Ùˆ)
- **Role**: AI calls as a patient representative (not responding to doctor)
- **Instructions**: Comprehensive Urdu script for greeting clinic, describing symptoms, and confirming appointments
- **Patient Context**: Passes patient name, symptoms, and appointment type to AI

### 2. Appointment Extraction (server.js)
- **New Endpoint**: `/api/extract-appointment`
- **AI Processing**: Uses GPT-4o to extract structured JSON from conversation transcript
- **Extracted Fields**:
  ```json
  {
    "appointment_confirmed": true/false,
    "date": "YYYY-MM-DD",
    "time": "HH:MM",
    "doctor_name": "string",
    "patient_name": "string",
    "appointment_type": "string",
    "notes": "string"
  }
  ```
- **Auto-callback**: Automatically sends confirmed appointments to LangGraph

### 3. Frontend Updates (App.js)
- Passes patient information to token endpoint
- Removed initial greeting (AI starts conversation)
- Collects complete conversation transcript
- Automatically extracts appointment on call end
- Shows appointment confirmation alert

## How It Works

### Flow:
```
1. LangGraph â†’ MCP Tool â†’ Node Backend
   â†“
2. Node sends call notification to React UI
   â†“
3. Doctor accepts call â†’ Request ephemeral token (with patient info)
   â†“
4. AI connects via WebRTC â†’ Starts speaking in Urdu
   â†“
5. AI: "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…ØŒ Ù…ÛŒÚº Ø§Ø­Ù…Ø¯ Ø®Ø§Ù† Ú©ÛŒ Ø·Ø±Ù Ø³Û’ ÙÙˆÙ† Ú©Ø± Ø±ÛØ§ ÛÙˆÚº..."
   â†“
6. Doctor responds in Urdu â†’ Conversation continues
   â†“
7. Appointment confirmed â†’ AI says "Ø´Ú©Ø±ÛŒÛØŒ Ù…Ù„Ø§Ù‚Ø§Øª Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ ÛÙˆ Ú¯Ø¦ÛŒ"
   â†“
8. Call ends â†’ Transcript sent to extraction endpoint
   â†“
9. GPT-4o extracts structured JSON
   â†“
10. Node sends to LangGraph callback
```

## Testing

### Quick Test:
```bash
# Terminal 1 - Start server
node server.js

# Terminal 2 - Open React app (in doctor-ui folder)
npm start

# Terminal 3 - Trigger test call
node test-call-trigger.js --quick
```

### What to Expect:
1. âœ… Browser shows incoming call with patient: "Ø§Ø­Ù…Ø¯ Ø®Ø§Ù†"
2. âœ… Accept call â†’ Microphone permission
3. âœ… AI starts speaking in Urdu automatically
4. âœ… Respond in Urdu to schedule appointment
5. âœ… End call â†’ Alert shows extracted appointment details
6. âœ… Check server logs for LangGraph callback

### Example AI Greeting (Urdu):
```
"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…ØŒ Ù…ÛŒÚº Ø§Ø­Ù…Ø¯ Ø®Ø§Ù† Ú©ÛŒ Ø·Ø±Ù Ø³Û’ ÙÙˆÙ† Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ” 
Ø§Ù†ÛÛŒÚº Ø¨Ø®Ø§Ø±ØŒ Ø³Ø± Ø¯Ø±Ø¯ Ø§ÙˆØ± Ú©Ú¾Ø§Ù†Ø³ÛŒ ØªÛŒÙ† Ø¯Ù† Ø³Û’ ÛÛ’Û” 
Ú©ÛŒØ§ Ø¢Ù¾ Ø¬Ù„Ø¯ Ø³Û’ Ø¬Ù„Ø¯ Ù…Ù„Ø§Ù‚Ø§Øª Ú©Ø§ ÙˆÙ‚Øª Ø¯Û’ Ø³Ú©ØªÛ’ ÛÛŒÚºØŸ"
```

Translation: "Peace be upon you, I am calling on behalf of Ahmed Khan. They have fever, headache and cough for three days. Can you give the earliest appointment time?"

## API Endpoints

### POST /api/get-ephemeral-token
**Request:**
```json
{
  "patientName": "Ø§Ø­Ù…Ø¯ Ø®Ø§Ù†",
  "symptoms": "Ø¨Ø®Ø§Ø±ØŒ Ø³Ø± Ø¯Ø±Ø¯",
  "appointmentType": "Ø¹Ø§Ù… Ù…Ø¹Ø§Ø¦Ù†Û"
}
```

**Response:**
```json
{
  "success": true,
  "client_secret": {
    "value": "eph_key_..."
  }
}
```

### POST /api/extract-appointment
**Request:**
```json
{
  "callId": "call_123",
  "transcript": [
    {"speaker": "AI", "text": "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…..."},
    {"speaker": "Doctor", "text": "ÙˆØ¹Ù„ÛŒÚ©Ù… Ø§Ù„Ø³Ù„Ø§Ù…..."}
  ]
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "appointment_confirmed": true,
    "date": "2025-11-21",
    "time": "14:00",
    "doctor_name": "Dr. Sarah",
    "patient_name": "Ø§Ø­Ù…Ø¯ Ø®Ø§Ù†",
    "appointment_type": "Ø¹Ø§Ù… Ù…Ø¹Ø§Ø¦Ù†Û",
    "notes": "Patient prefers afternoon"
  }
}
```

## Troubleshooting

### AI Not Speaking in Urdu?
- Check server logs for token generation
- Verify OpenAI API key has Realtime API access
- Check browser console for WebRTC connection status

### Appointment Not Extracted?
- Check transcript in browser console
- Verify conversation contains appointment details
- Check server logs for extraction errors

### No Audio?
- Ensure microphone permissions granted
- Check browser console for audio element logs
- Verify WebRTC connection established

## Console Logs to Monitor

### Server:
```
ğŸ”‘ Generating ephemeral token for WebRTC...
âœ… Ephemeral token generated successfully
ğŸ¤– === EXTRACTING APPOINTMENT DETAILS ===
âœ… Extracted appointment data: {...}
ğŸ“¤ Sending confirmed appointment to LangGraph...
```

### Browser:
```
âœ… Ephemeral token received
ğŸ¤ Microphone connected
ğŸ“¡ Data channel opened - AI will start speaking in Urdu
ğŸ”Š Received audio track from OpenAI
âœ… Audio playback started
ğŸ¤– AI said: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…...
ğŸ‘¨â€âš•ï¸ Doctor said: ÙˆØ¹Ù„ÛŒÚ©Ù… Ø§Ù„Ø³Ù„Ø§Ù…...
```

## Next Steps

1. **Refresh Browser**: Reload http://localhost:3000 to load updated code
2. **Test Call**: Run `node test-call-trigger.js --quick`
3. **Accept Call**: Click "Accept Call" in browser
4. **Speak in Urdu**: Respond to AI in Urdu
5. **End Call**: Click "End Call" to see extraction

## Files Modified
- âœ… `server.js` - Urdu instructions + extraction endpoint
- âœ… `doctor-ui/src/App.js` - Patient context + transcript collection
- âœ… `test-call-trigger.js` - Urdu test data

---

**Status**: ğŸŸ¢ System Ready
**Language**: ğŸ‡µğŸ‡° Urdu (Ø§Ø±Ø¯Ùˆ)
**AI Model**: gpt-4o-realtime-preview-2024-12-17
**Extraction Model**: gpt-4o (with JSON mode)
